{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhJaCyPNcWbG",
        "outputId": "8411035e-949d-4b26-9e7b-0affe796f82f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 998, done.\u001b[K\n",
            "remote: Total 998 (delta 0), reused 0 (delta 0), pack-reused 998\u001b[K\n",
            "Receiving objects: 100% (998/998), 69.77 MiB | 26.65 MiB/s, done.\n",
            "Resolving deltas: 100% (467/467), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy_VlJOsd_nJ",
        "outputId": "052c3b7e-dea0-4305-8a3e-800a99aec729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxS5yJL3d_6I",
        "outputId": "f2079a58-f071-4412-80ef-6a0e37b05e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-22 14:33:55--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221122T143355Z&X-Amz-Expires=300&X-Amz-Signature=350831d6b0d3d5dda4ce607cb19808dfa7427d3de6d5e2242a32760b8165ecbb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-22 14:33:55--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221122%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221122T143355Z&X-Amz-Expires=300&X-Amz-Signature=350831d6b0d3d5dda4ce607cb19808dfa7427d3de6d5e2242a32760b8165ecbb&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75587165 (72M) [application/octet-stream]\n",
            "Saving to: â€˜yolov7.ptâ€™\n",
            "\n",
            "yolov7.pt           100%[===================>]  72.08M  33.2MB/s    in 2.2s    \n",
            "\n",
            "2022-11-22 14:33:58 (33.2 MB/s) - â€˜yolov7.ptâ€™ saved [75587165/75587165]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip --quiet install onnx onnxruntime onnxsim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YltLvE_AeA4J",
        "outputId": "a49397f9-b000-4b78-9949-eaf6d617d01e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.1 MB 6.8 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.5 MB 38.1 MB/s \n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/94/00/4c748982170497008d3e62bbd6eaa2cb378b9cc9253c1b87a6875d09015a/onnxsim-0.4.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\u001b[0m\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0 MB 7.9 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46 kB 3.5 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 237 kB 56.9 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86 kB 4.8 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51 kB 7.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python export.py --weights yolov7.pt --grid --simplify  --img-size 640 640 --max-wh 640 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdMP8YPLeCKB",
        "outputId": "feac1837-d9fd-45f9-b55f-2056a44dd1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Import onnx_graphsurgeon failure: No module named 'onnx_graphsurgeon'\n",
            "Namespace(batch_size=1, conf_thres=0.25, device='cpu', dynamic=False, dynamic_batch=False, end2end=False, fp16=False, grid=True, img_size=[640, 640], include_nms=False, int8=False, iou_thres=0.45, max_wh=640, simplify=True, topk_all=100, weights='yolov7.pt')\n",
            "YOLOR ðŸš€ v0.1-115-g072f76c torch 1.12.1+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "Model Summary: 306 layers, 36905341 parameters, 36905341 gradients\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\n",
            "Starting TorchScript export with torch 1.12.1+cu113...\n",
            "/content/yolov7/models/yolo.py:52: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
            "TorchScript export success, saved as yolov7.torchscript.pt\n",
            "CoreML export failure: No module named 'coremltools'\n",
            "\n",
            "Starting TorchScript-Lite export with torch 1.12.1+cu113...\n",
            "TorchScript-Lite export success, saved as yolov7.torchscript.ptl\n",
            "\n",
            "Starting ONNX export with onnx 1.12.0...\n",
            "/content/yolov7/models/yolo.py:582: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if augment:\n",
            "/content/yolov7/models/yolo.py:614: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if profile:\n",
            "/content/yolov7/models/yolo.py:629: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if profile:\n",
            "\n",
            "Starting to simplify ONNX...\n",
            "ONNX export success, saved as yolov7.onnx\n",
            "\n",
            "Export complete (48.03s). Visualize with https://github.com/lutzroeder/netron.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "from utils.torch_utils import  time_synchronized, TracedModel\n",
        "import numpy as np\n",
        "from models.experimental import attempt_load\n",
        "import torch"
      ],
      "metadata": {
        "id": "QhtgVrMAfSzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = \"/content/yolov7/yolov7.onnx\"\n",
        "device='cpu'\n",
        "cuda=False\n",
        "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']\n",
        "session = ort.InferenceSession(w, providers=providers)\n",
        "\n",
        "#Getting onnx graph input and output names.\n",
        "outname = [i.name for i in session.get_outputs()]\n",
        "inname = [i.name for i in session.get_inputs()]"
      ],
      "metadata": {
        "id": "7PB6lBxKeDSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running inference using session.\n",
        "\n",
        "#Create random input.\n",
        "inp=np.random.rand(1,3,640,640)\n",
        "inp=inp.astype('float32')\n",
        "inp = {inname[0]:inp}\n",
        "#Warmup.\n",
        "outputs = session.run(outname, inp)[0]\n",
        "t1=time_synchronized()\n",
        "for _ in range(100):\n",
        " \n",
        "  outputs = session.run(outname, inp)[0]\n",
        "t2=time_synchronized() \n",
        "\n",
        "print('Time taken ONNX=',(t2-t1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5utqglYDfK7Z",
        "outputId": "d5a8efd8-047a-46e9-d38a-957c336afaf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken ONNX= 167.90548276901245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path='/content/yolov7/yolov7.pt'\n",
        "img_size=640\n",
        "model = attempt_load(weights_path, map_location=device)  # load FP32 model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yre_PjAiiyjp",
        "outputId": "86576d4c-85c8-43a1-de28-c8b6d29c6a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " model = TracedModel(model, device, img_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06E6V5ZMinM4",
        "outputId": "850a8df2-80c4-4ffc-edb8-d86f04488746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Convert model to Traced-model... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:477.)\n",
            "  return self._grad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_t=inp['images']\n",
        "inp_t=torch.from_numpy(inp_t)\n",
        "if device=='cuda':\n",
        "  inp_t=inp_t.cuda()\n",
        "pred=model(inp_t)\n",
        "\n",
        "t1=time_synchronized()\n",
        "for _ in range(100):\n",
        "  pred=model(inp_t)\n",
        "  \n",
        "t2=time_synchronized()\n",
        "print('Time taken=',(t2-t1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-iKmQZZjcrB",
        "outputId": "e452ec17-d62b-45c6-d007-c4e1aefb1abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken= 216.3110785484314\n"
          ]
        }
      ]
    }
  ]
}